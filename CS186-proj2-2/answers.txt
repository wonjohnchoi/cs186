Wonjohn Choi (cs186-de)
Jisoo Kim (cs186-if)

1. There was no special algorithms for aggregators. In IntegerAggregator, for AVG, we decided to calculate the average in the iterator(), not in mergeTuplesIntoGroup(). 
   For HeapFile.insertTuple(), we decided to change BufferPool.getPage() in order to add a new page to the file when there's no more free pages to add a tuple. So we call HeapFile.writePage() in BufferPool.getPage().

For Join, we first checked if all tuples in either child1 or child2 can fit in one page. If either of them can fit in a page, we make the one that fits in a page to be on the outer loop. Then, store all tuples in the page in an internal data structure, so we only have cost of looping over inner loop. If neither of them fit in a page, we do page-oriented nested loop join.

For BufferPool, we use TreeMap<Long, PageId> to store the time a page was stored in BufferPool and PageId. With this, in evictPage, we can efficiently find the PageId with the lowest associated time, which is the least recently used PageId (LRU). This approach has a tradeoff though: when user searches for a page id that is already in bufferpool, it takes O(n) time to update time field of the tree map.

2. In HeapFile.readPage(), we decided to throw an IllegalArgumentException() whenever a page doesn't exist so that BufferPool.getPage() can catch it and fetch a new page.

3. We did not miss any elements.

4.
Wonjohn and Jisoo both worked on implementation of BufferPool.

Wonjohn mainly worked on implementation and debugging of Predicate, JoinPredicate, Filter, Join, Insert, Delete, BufferPool.

Jisoo mainly worked on implementation and debugging of Aggregate, IntegerAggregator, StringAggregator, HeapPage, HeapFile.

5. Wonjohn used roughly 15 hours on the project. Jisoo used roughly 15 hours on the project.

We didn't find anything particularly difficult or confusing.
